{"cells":[{"cell_type":"markdown","metadata":{"id":"e6jlRXUwS6Kz"},"source":["# Preprocessing\n","讀取資料"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:27:31.589913Z","iopub.status.busy":"2024-06-13T02:27:31.589469Z","iopub.status.idle":"2024-06-13T02:27:32.707418Z","shell.execute_reply":"2024-06-13T02:27:32.706182Z","shell.execute_reply.started":"2024-06-13T02:27:31.589879Z"},"id":"siJzE3ttcNvI","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:27:32.710378Z","iopub.status.busy":"2024-06-13T02:27:32.709752Z","iopub.status.idle":"2024-06-13T02:27:36.999998Z","shell.execute_reply":"2024-06-13T02:27:36.998511Z","shell.execute_reply.started":"2024-06-13T02:27:32.710337Z"},"id":"1s6TC9qrd3hg","trusted":true},"outputs":[],"source":["# path = \"/content/drive/MyDrive/\"\n","# path = ''\n","path = '/kaggle/input/'\n","\n","train_df = pd.read_csv(path + \"store-sales-time-series-forecasting/train.csv\")\n","holiday_event_df = pd.read_csv(path + \"store-sales-time-series-forecasting/holidays_events.csv\")\n","stores_df = pd.read_csv(path + \"store-sales-time-series-forecasting/stores.csv\")\n","# transaction_df = pd.read_csv(path + \"store-sales-time-series-forecasting/transactions.csv\")\n","oil_df = pd.read_csv(path + \"store-sales-time-series-forecasting/oil.csv\")\n","test_df = pd.read_csv(path + \"store-sales-time-series-forecasting/test.csv\")"]},{"cell_type":"markdown","metadata":{"id":"ikQyHbDjS9tt"},"source":["擷取2015/08/15~2017/08/15的資料（共兩年）"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:27:37.001738Z","iopub.status.busy":"2024-06-13T02:27:37.001376Z","iopub.status.idle":"2024-06-13T02:27:37.707622Z","shell.execute_reply":"2024-06-13T02:27:37.706323Z","shell.execute_reply.started":"2024-06-13T02:27:37.001707Z"},"id":"BoWzpI94gS1q","trusted":true},"outputs":[],"source":["train_df['date'] = pd.to_datetime(train_df['date'])\n","oil_df['date'] = pd.to_datetime(oil_df['date'])\n","holiday_event_df['date'] = pd.to_datetime(holiday_event_df['date'])\n","# transaction_df['date'] = pd.to_datetime(transaction_df['date'])\n","test_df['date'] = pd.to_datetime(test_df['date'])\n","# reindex oil data\n","oil_df = oil_df.merge(\n","    pd.DataFrame({\"date\": pd.date_range(train_df.date.min().date(), test_df.date.max().date())}),\n","    on=\"date\",\n","    how=\"outer\",\n",").sort_values(\"date\", ignore_index=True)\n","\n","# fill missing values using linear interpolation\n","oil_df.dcoilwtico = oil_df.dcoilwtico.interpolate(method=\"linear\", limit_direction=\"both\")\n","\n","train_df = train_df[(train_df['date'] >= '2014-08-15') & (train_df['date'] <= '2017-12-31')]\n","holiday_event_df = holiday_event_df[(holiday_event_df['date'] >= '2014-08-15') & (holiday_event_df['date'] <= '2017-12-31')]\n","oil_df = oil_df[(oil_df['date'] >= '2014-08-15') & (oil_df['date'] <= '2017-12-31')]\n","# transaction_df = transaction_df[(transaction_df['date'] >= '2015-08-15') & (transaction_df['date'] <= '2017-12-31')]\n","test_df = test_df[(test_df['date'] >= '2014-08-15') & (test_df['date'] <= '2017-12-31')]"]},{"cell_type":"markdown","metadata":{"id":"y_Jrzhw7TIE6"},"source":["合併資料"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:27:37.711368Z","iopub.status.busy":"2024-06-13T02:27:37.710907Z","iopub.status.idle":"2024-06-13T02:27:38.294631Z","shell.execute_reply":"2024-06-13T02:27:38.293330Z","shell.execute_reply.started":"2024-06-13T02:27:37.711328Z"},"id":"ckNOJUh6eUhg","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1949508\n","28512\n","1949508\n"]}],"source":["print(len(train_df))\n","print(len(test_df))\n","train_df = pd.merge(train_df, oil_df, on='date', how='left')\n","train_df = pd.merge(train_df, stores_df, on='store_nbr', how='left')\n","# train_df = pd.merge(train_df, transaction_df, on=['date', 'store_nbr'], how='left')\n","test_df = pd.merge(test_df, oil_df, on='date', how='left')\n","test_df = pd.merge(test_df, stores_df, on='store_nbr', how='left')\n","print(train_df['id'].nunique())\n","\n","del oil_df, stores_df"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:27:38.296507Z","iopub.status.busy":"2024-06-13T02:27:38.296110Z","iopub.status.idle":"2024-06-13T02:27:46.211332Z","shell.execute_reply":"2024-06-13T02:27:46.210203Z","shell.execute_reply.started":"2024-06-13T02:27:38.296477Z"},"id":"KHJoakmHoiCV","trusted":true},"outputs":[],"source":["national_df = holiday_event_df[holiday_event_df['locale'] == 'National']\n","national_df = national_df.drop_duplicates(subset='date', keep='first')\n","train_national_df = pd.merge(train_df, national_df, on='date', how='left')\n","non_national_df = holiday_event_df[holiday_event_df['locale'] != 'National']\n","non_national_df = non_national_df.drop_duplicates(subset=['date', 'locale_name'], keep='first')\n","train_non_national_df = pd.merge(train_df, non_national_df, left_on=['date', 'city'], right_on=['date', 'locale_name'], how='left')\n","train_df = train_national_df.combine_first(train_non_national_df)\n","\n","test_national_df = pd.merge(test_df, national_df, on='date', how='left')\n","test_non_national_df = pd.merge(test_df, non_national_df, left_on=['date', 'city'], right_on=['date', 'locale_name'], how='left')\n","test_df = test_national_df.combine_first(test_non_national_df)\n","\n","del national_df, non_national_df, train_national_df, train_non_national_df, test_national_df, test_non_national_df"]},{"cell_type":"markdown","metadata":{"id":"iSPCTl68pbRc"},"source":["欄位名稱轉換（因為原始資料集有兩個type欄位分別在holiday_event_df跟stores_df）\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:27:46.213416Z","iopub.status.busy":"2024-06-13T02:27:46.213053Z","iopub.status.idle":"2024-06-13T02:27:46.406859Z","shell.execute_reply":"2024-06-13T02:27:46.405592Z","shell.execute_reply.started":"2024-06-13T02:27:46.213373Z"},"id":"K_8qbMxqeXvn","trusted":true},"outputs":[],"source":["train_df = train_df.rename(columns={'type_x': 'store_type', 'type_y': 'event_type'})\n","test_df = test_df.rename(columns={'type_x': 'store_type', 'type_y': 'event_type'})"]},{"cell_type":"markdown","metadata":{"id":"LfKLMKT4uHJD"},"source":["特徵工程（1. 日期欄位拆分、2. 數值欄位 min-max normalization）"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:27:46.408449Z","iopub.status.busy":"2024-06-13T02:27:46.408145Z","iopub.status.idle":"2024-06-13T02:27:46.644843Z","shell.execute_reply":"2024-06-13T02:27:46.643701Z","shell.execute_reply.started":"2024-06-13T02:27:46.408423Z"},"id":"58RA8hIDsIM2","trusted":true},"outputs":[],"source":["# 日期欄位拆分\n","train_df['year'] = train_df['date'].dt.year\n","train_df['month'] = train_df['date'].dt.month\n","train_df['day'] = train_df['date'].dt.day\n","train_df['day_of_week'] = train_df['date'].dt.dayofweek\n","\n","test_df['year'] = test_df['date'].dt.year\n","test_df['month'] = test_df['date'].dt.month\n","test_df['day'] = test_df['date'].dt.day\n","test_df['day_of_week'] = test_df['date'].dt.dayofweek"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:27:46.646484Z","iopub.status.busy":"2024-06-13T02:27:46.646099Z","iopub.status.idle":"2024-06-13T02:27:46.767324Z","shell.execute_reply":"2024-06-13T02:27:46.766221Z","shell.execute_reply.started":"2024-06-13T02:27:46.646454Z"},"id":"iemN5u_Xpzu_","trusted":true},"outputs":[],"source":["# 數值欄位 min-max normalization\n","columns_to_normalize = ['onpromotion', 'dcoilwtico']\n","train_df[columns_to_normalize] = (train_df[columns_to_normalize] - train_df[columns_to_normalize].min()) / (train_df[columns_to_normalize].max() - train_df[columns_to_normalize].min())\n","test_df[columns_to_normalize] = (test_df[columns_to_normalize] - train_df[columns_to_normalize].min()) / (test_df[columns_to_normalize].max() - train_df[columns_to_normalize].min())"]},{"cell_type":"markdown","metadata":{"id":"MObR8EiJT7V-"},"source":["新增經緯度欄位"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:27:46.790959Z","iopub.status.busy":"2024-06-13T02:27:46.790587Z","iopub.status.idle":"2024-06-13T02:29:24.877700Z","shell.execute_reply":"2024-06-13T02:29:24.876151Z","shell.execute_reply.started":"2024-06-13T02:27:46.790922Z"},"id":"o7_cRfCkMXEf","trusted":true},"outputs":[],"source":["cities_coordinates = {\n","    \"Quito\": {\"lat\": -0.1806532, \"lon\": -78.4678382},\n","    \"Guayaquil\": {\"lat\": -2.1709979, \"lon\": -79.9223592},\n","    \"Santo Domingo\": {\"lat\": -0.2530494, \"lon\": -79.1753765},\n","    \"Cuenca\": {\"lat\": -2.9001285, \"lon\": -79.0058965},\n","    \"Latacunga\": {\"lat\": -0.9393387, \"lon\": -78.6155545},\n","    \"Manta\": {\"lat\": -0.9676533, \"lon\": -80.7089101},\n","    \"Machala\": {\"lat\": -3.2581112, \"lon\": -79.9553924},\n","    \"Ambato\": {\"lat\": -1.2416666, \"lon\": -78.6195459},\n","    \"Quevedo\": {\"lat\": -1.0225124, \"lon\": -79.4604035},\n","    \"Esmeraldas\": {\"lat\": 0.9681789, \"lon\": -79.6517202},\n","    \"Loja\": {\"lat\": -3.9931283, \"lon\": -79.2042216},\n","    \"Libertad\": {\"lat\": -2.2311612, \"lon\": -80.9008852},\n","    \"Playas\": {\"lat\": -2.6284683, \"lon\": -80.3895886},\n","    \"Daule\": {\"lat\": -1.8621807, \"lon\": -79.9776688},\n","    \"Babahoyo\": {\"lat\": -1.8019264, \"lon\": -79.5346458},\n","    \"Cayambe\": {\"lat\": 0.0430556, \"lon\": -78.1459943},\n","    \"Salinas\": {\"lat\": -2.2171001, \"lon\": -80.9586051},\n","    \"Puyo\": {\"lat\": -1.4923925, \"lon\": -78.0024134},\n","    \"Guaranda\": {\"lat\": -1.5904732, \"lon\": -79.0022925},\n","    \"Ibarra\": {\"lat\": 0.3517083, \"lon\": -78.1223373},\n","    \"Riobamba\": {\"lat\": -1.6635508, \"lon\": -78.654646},\n","    \"El Carmen\": {\"lat\": -0.2687816, \"lon\": -79.466199}\n","}\n","\n","train_df['coordinates'] = train_df['city'].map(cities_coordinates)\n","test_df['coordinates'] = test_df['city'].map(cities_coordinates)\n","\n","train_df['longitude'] = train_df['coordinates'].map(lambda x: x['lon'] if x is not None else None)\n","train_df['latitude'] = train_df['coordinates'].map(lambda x: x['lat'] if x is not None else None)\n","test_df['longitude'] = test_df['coordinates'].map(lambda x: x['lon'] if x is not None else None)\n","test_df['latitude'] = test_df['coordinates'].map(lambda x: x['lat'] if x is not None else None)\n","\n","train_df.drop('coordinates', axis=1, inplace=True)\n","test_df.drop('coordinates', axis=1, inplace=True)\n","\n","# convert day_of_week to sin and cos\n","train_df['day_of_week_sin'] = np.sin(2 * np.pi * train_df['day_of_week']/7.0)\n","train_df['day_of_week_cos'] = np.cos(2 * np.pi * train_df['day_of_week']/7.0)\n","test_df['day_of_week_sin'] = np.sin(2 * np.pi * test_df['day_of_week']/7.0)\n","test_df['day_of_week_cos'] = np.cos(2 * np.pi * test_df['day_of_week']/7.0)\n","\n","\n","# Use one-hot encoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","one_hot_col = ['store_type']\n","\n","# Instantiate and fit the OneHotEncoder\n","enc = OneHotEncoder(sparse=False)\n","enc.fit(train_df[one_hot_col])\n","\n","# Transform the data\n","train_one_hot = enc.transform(train_df[one_hot_col])\n","test_one_hot = enc.transform(test_df[one_hot_col])\n","\n","# Get the feature names\n","feature_names = enc.get_feature_names_out(one_hot_col)\n","\n","# Create DataFrames from the one-hot encoded arrays\n","train_one_hot_df = pd.DataFrame(train_one_hot, columns=feature_names, index=train_df.index)\n","test_one_hot_df = pd.DataFrame(test_one_hot, columns=feature_names, index=test_df.index)\n","\n","\n","# Concatenate the one-hot encoded columns to the original DataFrames\n","train_df = pd.concat([train_df, train_one_hot_df], axis=1)\n","test_df = pd.concat([test_df, test_one_hot_df], axis=1)\n","\n","# Drop the original columns\n","train_df.drop(one_hot_col, axis=1, inplace=True)\n","test_df.drop(one_hot_col, axis=1, inplace=True)\n","\n","del train_one_hot_df, test_one_hot_df, feature_names, enc\n","# Display the DataFrames to check the results\n","# print(train_df.head())\n","# print(test_df.head())\n","\n","\n","def replace_transfer(row):\n","    if row['event_type'] == 'Holiday':\n","        if row['transferred'] == 1:\n","            return 0\n","        return 1\n","    elif row['event_type'] == 'Transfer':\n","        return 1\n","    elif row['event_type'] == 'Additional':\n","        return 1\n","    elif row['event_type'] == 'Bridge':\n","        return 1\n","    return 0\n","\n","def isEvent(row):\n","    if row['event_type'] == 'Event':\n","        return 1\n","    return 0\n","\n","train_df['isHoliday'] = train_df.apply(replace_transfer, axis=1)\n","train_df['isEvent'] = train_df.apply(isEvent, axis=1)\n","test_df['isHoliday'] = test_df.apply(replace_transfer, axis=1)\n","test_df['isEvent'] = test_df.apply(isEvent, axis=1)\n","\n","train_df['dcoilwtico'].fillna(train_df['dcoilwtico'].mean(), inplace=True)\n","test_df['dcoilwtico'].fillna(train_df['dcoilwtico'].mean(), inplace=True)\n","train_df = train_df.drop(['description', 'city', 'state', 'cluster', 'year', 'event_type', 'locale', 'locale_name', 'transferred'], axis=1)\n","test_df = test_df.drop(['description', 'city', 'state', 'cluster', 'year', 'event_type', 'locale', 'locale_name', 'transferred'], axis=1)"]},{"cell_type":"markdown","metadata":{"id":"NtdppfYVUCc6"},"source":["把sales欄位放到資料集最後，作為y_train"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:29:24.879732Z","iopub.status.busy":"2024-06-13T02:29:24.879221Z","iopub.status.idle":"2024-06-13T02:29:24.982482Z","shell.execute_reply":"2024-06-13T02:29:24.981272Z","shell.execute_reply.started":"2024-06-13T02:29:24.879688Z"},"id":"aEW6PqSWCVRH","trusted":true},"outputs":[],"source":["cols = [col for col in train_df.columns if col != 'sales']\n","cols.append('sales')\n","train_df = train_df[cols]\n","# test_df = test_df[cols]"]},{"cell_type":"markdown","metadata":{},"source":["# Transformation\n","## Multi-Index"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:29:24.991593Z","iopub.status.busy":"2024-06-13T02:29:24.991173Z","iopub.status.idle":"2024-06-13T02:29:26.139378Z","shell.execute_reply":"2024-06-13T02:29:26.138334Z","shell.execute_reply.started":"2024-06-13T02:29:24.991560Z"},"trusted":true},"outputs":[],"source":["# conduct multiindex\n","train_df['date'] = train_df.date.dt.to_period('D')\n","test_df['date'] = test_df.date.dt.to_period('D')\n","\n","# Set the new index\n","train_df = (train_df\n","       .set_index(['date', 'family', 'store_nbr'])         # Setting MultiIndex to make unique identifiers for each 'sales' item\n","       .sort_index()\n","      )\n","\n","test_df = (test_df\n","       .set_index(['date', 'family', 'store_nbr'])         # Setting MultiIndex to make unique identifiers for each 'sales' item\n","       .sort_index()\n","      )"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:29:26.141136Z","iopub.status.busy":"2024-06-13T02:29:26.140761Z","iopub.status.idle":"2024-06-13T02:29:27.554301Z","shell.execute_reply":"2024-06-13T02:29:27.553084Z","shell.execute_reply.started":"2024-06-13T02:29:26.141107Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1094, 30294)\n","(16, 30294)\n"]}],"source":["X_train = train_df.copy()\n","X_test = test_df.copy()\n","\n","del train_df, test_df\n","# Pivot the table to get the desired structure\n","y_train = (X_train\n","           .unstack(['family', 'store_nbr'])\n","           .loc[:,\"sales\"]\n","          )\n","\n","X_train = (X_train\n","           .unstack(['family', 'store_nbr'])\n","           .loc[:, X_train.columns[0]:X_train.columns[-1]]\n","          )\n","# print(X_train.shape)\n","\n","X_test = (X_test\n","          .unstack(['family', 'store_nbr'])\n","          .loc[:, X_test.columns[0]:X_test.columns[-1]]\n","         )\n","# get X_test have same columns as X_train\n","X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n","\n","X_train_id = X_train['id']\n","X_test_id = X_test['id']\n","\n","X_train = X_train.drop('id', axis=1)\n","X_test = X_test.drop('id', axis=1)\n","\n","# drop duplicated columns\n","X_train_dup_columns = ~X_train.columns.duplicated()\n","X_train = X_train.loc[:,X_train_dup_columns]\n","X_test = X_test.loc[:,X_train_dup_columns]\n","\n","print(X_train.shape)\n","print(X_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Single-Index"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:29:27.556371Z","iopub.status.busy":"2024-06-13T02:29:27.555910Z","iopub.status.idle":"2024-06-13T02:29:27.563558Z","shell.execute_reply":"2024-06-13T02:29:27.562337Z","shell.execute_reply.started":"2024-06-13T02:29:27.556331Z"},"trusted":true},"outputs":[],"source":["# # split data by store_nbr and family\n","# store_nbrs = train_df['store_nbr'].unique()\n","# families = train_df['family'].unique()\n","# train_famlies_df = []\n","# train_stores_df = []\n","# test_famlies_df = []\n","# test_stores_df = []\n","# test_id_df = []\n","# for i, family in enumerate(families):\n","#     train_famlies_df.append([])\n","#     test_famlies_df.append([])\n","#     test_id_df.append([])\n","#     for j, store_nbr in enumerate(store_nbrs):\n","#         df = train_df[(train_df['store_nbr'] == store_nbr) & (train_df['family'] == family)]\n","#         df_test = test_df[(test_df['store_nbr'] == store_nbr) & (test_df['family'] == family)]\n","#         # sort by date\n","#         df = df.sort_values(by='date')\n","#         df_test = df_test.sort_values(by='date')\n","\n","#         test_id_df[i].append(df_test[['id']])\n","#         # drop date column\n","#         df = df.drop(['date', 'id', 'family', 'store_nbr'], axis=1)\n","#         df_test = df_test.drop(['date', 'id', 'family', 'store_nbr'], axis=1)\n","        \n","#         if len(df) > 0:\n","#             train_famlies_df[i].append(df)\n","#         if len(df_test) > 0:\n","#             test_famlies_df[i].append(df_test)"]},{"cell_type":"markdown","metadata":{},"source":["# LSTM Model\n","## Multi-Index"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T02:29:27.585009Z","iopub.status.busy":"2024-06-13T02:29:27.584605Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-13 02:29:29.765311: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-13 02:29:29.765478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-13 02:29:29.912781: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["(1063, 32, 30294)\n","(1063, 1782)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30294</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1782</span>)       │   <span style=\"color: #00af00; text-decoration-color: #00af00\">228,644,856</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1782</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1782</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,411,320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1782</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1782</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,177,306</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30294\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1782\u001b[0m)       │   \u001b[38;5;34m228,644,856\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1782\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1782\u001b[0m)           │    \u001b[38;5;34m25,411,320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1782\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1782\u001b[0m)           │     \u001b[38;5;34m3,177,306\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">257,233,482</span> (981.27 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m257,233,482\u001b[0m (981.27 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">257,233,482</span> (981.27 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m257,233,482\u001b[0m (981.27 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n"]}],"source":["#### construct LSTM model with keras\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","from keras.layers import Embedding\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers import concatenate\n","\n","\n","def create_sequences(data_X, data_Y, time_steps=1):\n","    x, y = [], []\n","    \n","    for i in range(len(data_X) - time_steps + 1):\n","        x.append(data_X.iloc[i:(i + time_steps)].values)\n","        y.append(data_Y.iloc[i + time_steps -1])\n","    return np.array(x), np.array(y)\n","\n","def create_model(input_shape, lstm_units=1782, dense_units=50, dropout_rate=0.2):\n","    input_layer = Input(shape=input_shape)\n","    # add multiple LSTM layers and dropout layers\n","    lstm_layer = LSTM(lstm_units, return_sequences=True)(input_layer)\n","    lstm_layer = Dropout(dropout_rate)(lstm_layer)\n","    lstm_layer = LSTM(lstm_units)(lstm_layer)\n","    lstm_layer = Dropout(dropout_rate)(lstm_layer)\n","    # add dense layer\n","    output_layer = Dense(1782, activation='relu')(lstm_layer)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    # compile with MSLE\n","    model.compile(optimizer='adam', loss='mean_squared_logarithmic_error')\n","    # show model summary\n","    model.summary()\n","    return model\n","\n","time_steps = 32\n","batch_size = 4\n","X_test.fillna(0, inplace=True)\n","complete_df = pd.concat([X_train, X_test], axis=0)\n","\n","X_train_seq, y_train_seq = create_sequences(X_train, y_train, time_steps)\n","# print(y_train_seq[0]\n","df_test = complete_df[len(X_train)-time_steps + 1:]\n","del complete_df, X_train\n","X_test_seq, y_test_seq = create_sequences(df_test, y_train, time_steps)\n","del df_test\n","print(X_train_seq.shape)\n","print(y_train_seq.shape)\n","model = create_model((X_train_seq.shape[1], X_train_seq.shape[2]))\n","model.fit(X_train_seq, y_train_seq, epochs=30, batch_size=batch_size, verbose=1)\n","y_pred = model.predict(X_test_seq, verbose=1)"]},{"cell_type":"markdown","metadata":{},"source":["## Single-Index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4c9N6JtRwWI","trusted":true},"outputs":[],"source":["# # construct LSTM model with keras\n","# from keras.models import Sequential\n","# from keras.layers import LSTM, Dense, Dropout\n","# from keras.layers import Embedding\n","# from keras.layers import Input\n","# from keras.models import Model\n","# from keras.layers import concatenate\n","\n","\n","# def create_sequences(data_X, data_Y, time_steps=1):\n","#     x, y = [], []\n","#     for i in range(len(data_X) - time_steps + 1):\n","#         x.append(data_X.iloc[i:(i + time_steps)].values)\n","#         y.append(data_Y.iloc[i + time_steps -1])\n","#     return np.array(x), np.array(y)\n","\n","# def create_model(input_shape, lstm_units=50, dense_units=50, dropout_rate=0.2):\n","#     input_layer = Input(shape=input_shape)\n","#     lstm_layer = LSTM(lstm_units)(input_layer)\n","#     output_layer = Dense(1)(lstm_layer)\n","#     model = Model(inputs=input_layer, outputs=output_layer)\n","#     model.compile(optimizer='adam', loss='mse')\n","#     return model\n","\n","# time_steps = 1\n","# batch_size = 128\n","\n","# for i in range(len(train_famlies_df)):\n","#     for j in range(len(train_famlies_df[i])):\n","#         df = train_famlies_df[i][j]\n","#         df_test = test_famlies_df[i][j]\n","#         if len(df) == 0 or len(df_test) == 0:\n","#             continue\n","#         complete_df = pd.concat([df, df_test])\n","#         X_train, y_train = create_sequences(df.drop('sales', axis=1), df[['sales']], time_steps)\n","#         df_test = complete_df[len(df)-time_steps + 1:]\n","#         X_test, y_test = create_sequences(df_test.drop('sales', axis=1), df_test[['sales']], time_steps)\n","#         model = create_model((X_train.shape[1], X_train.shape[2]))\n","#         model.fit(X_train, y_train, epochs=10, batch_size=batch_size, verbose=0)\n","#         y_pred = model.predict(X_test, verbose=0)\n","#         test_id_df[i][j]['sales'] = y_pred\n","#         del model, X_train, y_train, X_test, y_test, complete_df, df, df_test, y_pred\n","#     print(i)"]},{"cell_type":"markdown","metadata":{},"source":["# Submission\n","## Single-Index"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # save prediction csv \n","# test_id_df_combined = pd.DataFrame()\n","# for i in range(len(test_id_df)):\n","#     for j in range(len(test_id_df[i])):\n","#         test_id_df_combined = pd.concat([test_id_df_combined, test_id_df[i][j]])\n","\n","# # merge test_id_df_combined with test_df\n","# test_df_result = pd.merge(test_df, test_id_df_combined, on='id', how='left')\n","# print(test_df_result)\n","\n","# test_df_result[['id', 'sales']].to_csv('/kaggle/working/submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Multi-Index"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Assuming y_pred is the predictions with shape (16, 1782)\n","# and X_test_id contains the original IDs corresponding to the same multi-indexed structure.\n","\n","# Step 1: Reshape y_pred to match the structure of test_df before MultiIndex\n","y_pred_df = pd.DataFrame(y_pred, index=X_test.index, columns=y_train.columns)\n","\n","# Step 2: Use X_test_id to map the predictions back to their original IDs\n","# Create a DataFrame to hold the IDs and predictions\n","predictions_df = y_pred_df.stack(['family', 'store_nbr']).reset_index()\n","predictions_df.columns = ['date', 'family', 'store_nbr', 'sales']\n","\n","# Add the original IDs\n","predictions_df['id'] = X_test_id.stack(['family', 'store_nbr']).values\n","\n","# Step 3: Reconstruct the test_df DataFrame using the original IDs and the predictions\n","# Assuming the original test_df had the columns ['id', 'date', 'family', 'store_nbr', 'sales']\n","final_df = predictions_df[['id', 'date', 'family', 'store_nbr', 'sales']]\n","\n","# Sort by 'id' if necessary\n","final_df = final_df.sort_values(by='id').reset_index(drop=True)\n","\n","# Display the final DataFrame\n","# print(final_df)\n","\n","submission_df = final_df[['id', 'sales']]\n","# Save to CSV if required\n","submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","print(submission_df)"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":2887556,"sourceId":29781,"sourceType":"competition"}],"dockerImageVersionId":30733,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
